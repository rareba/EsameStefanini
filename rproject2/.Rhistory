library("ggthemes", lib.loc="C:/Users/GiulioVannini/Documents/R/win-library/3.3")
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
library("rstan", lib.loc="C:/Users/GiulioVannini/Documents/R/win-library/3.3")
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha0; int beta0; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha0,beta0); Y ~ poisson(Lambda); }
'
# 2) Ottieni un campione simulato dalla a-posteriori
require(rstan)
library("rstudioapi", lib.loc="C:/Users/GiulioVannini/Documents/R/win-library/3.3")
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();
c(iniTime = iniTime, endTime = endTime)
#SAMPLING E GENERAZIONE DELLE CATENE 
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.  #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997, #init= list( #      as.list(initPara()), #      as.list(initPara()), #      as.list(initPara()), #      as.list(initPara())),                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) ) #time
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
mod <- stan_model(model_code = modPG)
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di outlput e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.  #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997, #init= list( #      as.list(initPara()), #      as.list(initPara()), #      as.list(initPara()), #      as.list(initPara())),                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) ) #time
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di outlput e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
# creiamo un file pdf di tutto l'output
ggmcmc(outSim)
###traceplots
library(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha0; int beta0; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha0,beta0); Y ~ poisson(Lambda); }
'
# 2) Ottieni un campione simulato dalla a-posteriori
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
#SAMPLING E GENERAZIONE DELLE CATENE 
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.  #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997, #init= list( #      as.list(initPara()), #      as.list(initPara()), #      as.list(initPara()), #      as.list(initPara())),                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) ) #time
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di outlput e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
# creiamo un file pdf di tutto l'output
ggmcmc(outSim)
###traceplots
library(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
ggs_traceplot(outSim) + theme_fivethirtyeight()
library(shiny) runApp()
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continous = "density"))
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
ggs_pairs(outSim, lower = list(continous = "density"))
ggs_pairs(outSim, lower = list(continous = "density"))
str(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continous = "density"))
ggs_pairs(outSim, lower = list(continous = "density"))
ggs_pairs(outSim, lower = list(continuous = "density"))
ggs_pairs(outSim, lower = list(continuous = "density"))
lower = list(continuous = "density")
ggs_pairs(outSim, lower)
ggs_pairs(outSim, lower = list(continuous = "density"))
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
# creiamo un file pdf di tutto l'output
ggmcmc(outSim)
###traceplots
library(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
str(outSim)
# riassunti numeri e diagnostica
summary(fit)
modPGp <- '
data { int N; int Y[N]; }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(95,18); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();
c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 6,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red")
mailO
mail
MailsOsservate
library(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
#SAMPLING E GENERAZIONE DELLE CATENE 
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.  #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di outlput e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
# creiamo un file pdf di tutto l'output
###traceplots
library(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
str(outSim)
ggs_pairs(outSim, lower = list(continuous = "density"))
ggs_pairs(outSim, lower = list(continuous = "density"))
str(outSim)
summary(fit)
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = Y, color = "red")
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9), color = "red")
y_osservate = c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = y_osservate, color = "red")
y_osservate <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = y_osservate, color = "red")
MailsOsservate <- c(mean(Y))
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red")
modPGp <- '
data { int N; int Y[N]; }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(95,18); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();
c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 6,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim = ggs(fit)
MailsOsservate <- c(mean(Y), Y)
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red")
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
ggs_density(outSim, family = "Y_predict") + geom_vline(c(xintercept = MailsOsservate, color = "red", xintercept = Y, color = "blue"))
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue")
modPGp <- '
data { int N; int Y[N]; }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(95,18); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();
c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 6,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha0; int beta0; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha0,beta0); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();
c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di output e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
# 4) Riassumi le caratteristiche principali della distribuzione a-posteriori
#   A vedere dal traceplot e dal density plot la sovrapposizione della 4 catene è buona. Magari dal density plot soprattutto si nota qualche discrepanza in più
#   Gelman invece mostra che non ci sono fattori di potenziale riduzione di scala per Lambda. Il che avalla la tesi sulla discreta bontà del modello.
#   Bontà avallata anche da Geweke, dato che tutte le catene sono comprese su valori Z fra -2 e 2
#   Il grafico Caterpillar mostra invece che la credibilità di lambda è alta fra circa 4,5 e 6,25
#   gg_pairs non funziona per qualche motivo
#   La funzione summary() aiuta a monitorare numericamente quanto detto fin'ora: vale a dire che le catene si sovrappongono e non ci sono problemi con il modello.
# 5) Ottieni la distribuzione prededittiva della futura osservazione con un campione di dimensione 10k. 
modPGp <- '
data { int N; int Y[N]; }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(95,18); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();
c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 6,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#    Riassumi le sue caratteristiche.
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue")
#    Mediamente arrivano 5,6 email al giorno. 
#    Il valore sta dentro alla distribuzione che risulta dal modello predittivo.
#    Si può dire che ci si può aspettare fra le 5 e le 6 email al giorno.
#    Guardando anche i valori osservati si può dire che in generale non ci sono "fughe" verso valori improbabili
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha0; int beta0; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha0,beta0); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();
c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di output e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha0; int beta0; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha0,beta0); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
Mod
mod
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha0; int beta0; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha0; int beta0; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha0; int beta0; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha0,beta0); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
modPG <- '
data { int N; int Y[N]; int alpha1; int beta1; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di output e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
# 4) Riassumi le caratteristiche principali della distribuzione a-posteriori
#   A vedere dal traceplot e dal density plot la sovrapposizione della 4 catene è buona. Magari dal density plot soprattutto si nota qualche discrepanza in più
#   Gelman invece mostra che non ci sono fattori di potenziale riduzione di scala per Lambda. Il che avalla la tesi sulla discreta bontà del modello.
#   Bontà avallata anche da Geweke, dato che tutte le catene sono comprese su valori Z fra -2 e 2
#   Il grafico Caterpillar mostra invece che la credibilità di lambda è alta fra circa 4,5 e 6,25
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#   A vedere dal traceplot e dal density plot la sovrapposizione della 4 catene è buona. Magari dal density plot soprattutto si nota qualche discrepanza in più
#   Gelman invece mostra che non ci sono fattori di potenziale riduzione di scala per Lambda. Il che avalla la tesi sulla discreta bontà del modello.
#   Bontà avallata anche da Geweke, dato che tutte le catene sono comprese su valori Z fra -2 e 2
#   Il grafico Caterpillar mostra invece che la credibilità di lambda è alta fra circa 4,5 e 6,25
#   gg_pairs non funziona per qualche motivo
#   La funzione summary() aiuta a monitorare numericamente quanto detto fin'ora: vale a dire che le catene si sovrappongono e non ci sono problemi con il modello.
# 5) Ottieni la distribuzione prededittiva della futura osservazione con un campione di dimensione 10k. 
modPGp <- '
data { int N; int Y[N]; }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();
c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 6,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#    Riassumi le sue caratteristiche.
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue")
#    Mediamente arrivano 5,6 email al giorno. 
#    Il valore sta dentro alla distribuzione che risulta dal modello predittivo.
#    Si può dire che ci si può aspettare fra le 5 e le 6 email al giorno.
#    Guardando anche i valori osservati si può dire che in generale non ci sono "fughe" verso valori improbabili
outSim = ggs(fit)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha0; int beta0; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha0,beta0); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di output e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
# 4) Riassumi le caratteristiche principali della distribuzione a-posteriori
#   A vedere dal traceplot e dal density plot la sovrapposizione della 4 catene è buona. Magari dal density plot soprattutto si nota qualche discrepanza in più
#   Gelman invece mostra che non ci sono fattori di potenziale riduzione di scala per Lambda. Il che avalla la tesi sulla discreta bontà del modello.
#   Bontà avallata anche da Geweke, dato che tutte le catene sono comprese su valori Z fra -2 e 2
#   Il grafico Caterpillar mostra invece che la credibilità di lambda è alta fra circa 4,5 e 6,25
#   gg_pairs non funziona per qualche motivo
#   La funzione summary() aiuta a monitorare numericamente quanto detto fin'ora: vale a dire che le catene si sovrappongono e non ci sono problemi con il modello.
# 5) Ottieni la distribuzione prededittiva della futura osservazione con un campione di dimensione 10k. 
modPGp <- '
data { int N; int Y[N]; }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();
c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 6,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#    Riassumi le sue caratteristiche.
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue")
#    Mediamente arrivano 5,6 email al giorno. 
#    Il valore sta dentro alla distribuzione che risulta dal modello predittivo.
#    Si può dire che ci si può aspettare fra le 5 e le 6 email al giorno.
#    Guardando anche i valori osservati si può dire che in generale non ci sono "fughe" verso valori improbabili
modPGp <- '
data { int N; int Y[N]; }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();
c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 6,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#    Riassumi le sue caratteristiche.
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue")
#    Mediamente arrivano 5,6 email al giorno. 
#    Il valore sta dentro alla distribuzione che risulta dal modello predittivo.
#    Si può dire che ci si può aspettare fra le 5 e le 6 email al giorno.
#    Guardando anche i valori osservati si può dire che in generale non ci sono "fughe" verso valori improbabili
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 4,                   iter = 10000,                   warmup = 0,                   thin = 1,                   cores = 6,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#    Riassumi le sue caratteristiche.
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue")
#    Mediamente arrivano 5,6 email al giorno. 
#    Il valore sta dentro alla distribuzione che risulta dal modello predittivo.
#    Si può dire che ci si può aspettare fra le 5 e le 6 email al giorno.
#    Guardando anche i valori osservati si può dire che in generale non ci sono "fughe" verso valori improbabili
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();
c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 0,                   thin = 1,                   cores = 6,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#    Riassumi le sue caratteristiche.
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue")
#    Mediamente arrivano 5,6 email al giorno. 
#    Il valore sta dentro alla distribuzione che risulta dal modello predittivo.
#    Si può dire che ci si può aspettare fra le 5 e le 6 email al giorno.
#    Guardando anche i valori osservati si può dire che in generale non ci sono "fughe" verso valori improbabili
hist(fit)
hist(fit)
hist(fit)
hist(outSim)
hist(outSim)
outSim
hist(outSim$value)
hist(outSim$value, breaks = 1000)
hist(outSim$value, breaks = 100)
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();
c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 1000,                   thin = 1,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#    Riassumi le sue caratteristiche.
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue")
hist(outSim$value, breaks = 100)
hist(outSim$value, breaks = 50)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 1000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#    Riassumi le sue caratteristiche.
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue")
#    Mediamente arrivano 5,6 email al giorno. 
#    Il valore sta dentro alla distribuzione che risulta dal modello predittivo.
#    Si può dire che ci si può aspettare fra le 5 e le 6 email al giorno.
#    Guardando anche i valori osservati si può dire che in generale non ci sono "fughe" verso valori improbabili
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();
c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 1000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#    Riassumi le sue caratteristiche.
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue")
#    Mediamente arrivano 5,6 email al giorno. 
#    Il valore sta dentro alla distribuzione che risulta dal modello predittivo.
#    Si può dire che ci si può aspettare fra le 5 e le 6 email al giorno.
#    Guardando anche i valori osservati si può dire che in generale non ci sono "fughe" verso valori improbabili
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha0; int beta0; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha0,beta0); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di output e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
# 4) Riassumi le caratteristiche principali della distribuzione a-posteriori
#   A vedere dal traceplot e dal density plot la sovrapposizione della 4 catene è buona. Magari dal density plot soprattutto si nota qualche discrepanza in più
#   Gelman invece mostra che non ci sono fattori di potenziale riduzione di scala per Lambda. Il che avalla la tesi sulla discreta bontà del modello.
#   Bontà avallata anche da Geweke, dato che tutte le catene sono comprese su valori Z fra -2 e 2
#   Il grafico Caterpillar mostra invece che la credibilità di lambda è alta fra circa 4,5 e 6,25
#   gg_pairs non funziona per qualche motivo
#   La funzione summary() aiuta a monitorare numericamente quanto detto fin'ora: vale a dire che le catene si sovrappongono e non ci sono problemi con il modello.
# 5) Ottieni la distribuzione prededittiva della futura osservazione con un campione di dimensione 10k. 
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();
c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 1000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#    Riassumi le sue caratteristiche.
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue")
#    Mediamente arrivano 5,6 email al giorno. 
#    Il valore sta dentro alla distribuzione che risulta dal modello predittivo.
#    Si può dire che ci si può aspettare fra le 5 e le 6 email al giorno.
#    Guardando anche i valori osservati si può dire che in generale non ci sono "fughe" verso valori improbabili
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 50)
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha0; int beta0; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha0,beta0); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di output e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
# 4) Riassumi le caratteristiche principali della distribuzione a-posteriori
#   A vedere dal traceplot e dal density plot la sovrapposizione della 4 catene è buona. Magari dal density plot soprattutto si nota qualche discrepanza in più
#   Gelman invece mostra che non ci sono fattori di potenziale riduzione di scala per Lambda. Il che avalla la tesi sulla discreta bontà del modello.
#   Bontà avallata anche da Geweke, dato che tutte le catene sono comprese su valori Z fra -2 e 2
#   Il grafico Caterpillar mostra invece che la credibilità di lambda è alta fra circa 4,5 e 6,25
#   gg_pairs non funziona per qualche motivo
#   La funzione summary() aiuta a monitorare numericamente quanto detto fin'ora: vale a dire che le catene si sovrappongono e non ci sono problemi con il modello.
# 5) Ottieni la distribuzione prededittiva della futura osservazione con un campione di dimensione 10k. 
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 1000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#    Riassumi le sue caratteristiche.
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_density(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue")
#    Mediamente arrivano 5,6 email al giorno. 
#    Il valore sta dentro alla distribuzione che risulta dal modello predittivo.
#    Si può dire che ci si può aspettare fra le 5 e le 6 email al giorno.
#    Guardando anche i valori osservati si può dire che in generale non ci sono "fughe" verso valori improbabili
hist(outSim$value, breaks = 50)
hist(outSim$value, breaks = 500)
hist(outSim$value, breaks = 150)
ggs_histogram(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue")
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha0; int beta0; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha0,beta0); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
# riassunti numeri e diagnostica
summary(fit)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha0; int beta0; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha0,beta0); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di output e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
#ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
# 4) Riassumi le caratteristiche principali della distribuzione a-posteriori
#   A vedere dal traceplot e dal density plot la sovrapposizione della 4 catene è buona. Magari dal density plot soprattutto si nota qualche discrepanza in più
#   Gelman invece mostra che non ci sono fattori di potenziale riduzione di scala per Lambda. Il che avalla la tesi sulla discreta bontà del modello.
#   Bontà avallata anche da Geweke, dato che tutte le catene sono comprese su valori Z fra -2 e 2
#   Il grafico Caterpillar mostra invece che la credibilità di lambda è alta fra circa 4,5 e 6,25
#   gg_pairs non funziona per qualche motivo
#   La funzione summary() aiuta a monitorare numericamente quanto detto fin'ora: vale a dire che le catene si sovrappongono e non ci sono problemi con il modello.
# 5) Ottieni la distribuzione prededittiva della futura osservazione con un campione di dimensione 10k. 
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 1000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
testModel2 <- stan(model_code = modPGp, data = data, iter = 10000, chains = 1)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha0; int beta0; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod, #DATI FORNITI Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9) N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha1; int beta1; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di output e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
#ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha1; int beta1; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di output e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# riassunti numeri e diagnostica
summary(fit)
# 4) Riassumi le caratteristiche principali della distribuzione a-posteriori
#   A vedere dal traceplot e dal density plot la sovrapposizione della 4 catene è buona. Magari dal density plot soprattutto si nota qualche discrepanza in più
#   Gelman invece mostra che non ci sono fattori di potenziale riduzione di scala per Lambda. Il che avalla la tesi sulla discreta bontà del modello.
#   Bontà avallata anche da Geweke, dato che tutte le catene sono comprese su valori Z fra -2 e 2
#   Il grafico Caterpillar mostra invece che la credibilità di lambda è alta fra circa 4,5 e 6,25
#   gg_pairs non funziona per qualche motivo
#   La funzione summary() aiuta a monitorare numericamente quanto detto fin'ora: vale a dire che le catene si sovrappongono e non ci sono problemi con il modello.
# 5) Ottieni la distribuzione prededittiva della futura osservazione con un campione di dimensione 10k. 
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 1000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
testModel2 <- stan(model_code = modPGp, data = data, iter = 10000, chains = 1)
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#    Riassumi le sue caratteristiche.
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_histogram(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue")
outSim
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
modPG <- '
modPG <- '
modPG <- '
modPG <- '
modPG <- '
modPG <- '
modPG <- '
data { int N; int Y[N]; int alpha1; int beta1; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time( system.time( library(rstudioapi) system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha1; int beta1; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha1; int beta1; } transformed data{ }
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha1; int beta1; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 1997,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha1; int beta1; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 'MinecraftSeed1986',                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha1; int beta1; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di output e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
#ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
# 4) Riassumi le caratteristiche principali della distribuzione a-posteriori
#   A vedere dal traceplot e dal density plot la sovrapposizione della 4 catene è buona. Magari dal density plot soprattutto si nota qualche discrepanza in più
#   Gelman invece mostra che non ci sono fattori di potenziale riduzione di scala per Lambda. Il che avalla la tesi sulla discreta bontà del modello.
#   Bontà avallata anche da Geweke, dato che tutte le catene sono comprese su valori Z fra -2 e 2
#   Il grafico Caterpillar mostra invece che la credibilità di lambda è alta fra circa 4,5 e 6,25
#   gg_pairs non funziona per qualche motivo
#   La funzione summary() aiuta a monitorare numericamente quanto detto fin'ora: vale a dire che le catene si sovrappongono e non ci sono problemi con il modello.
# 5) Ottieni la distribuzione prededittiva della futura osservazione con un campione di dimensione 10k. 
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
rtvs::debug_source("~/visual studio 2017/Projects/rproject2/rproject2/script.R")
rtvs::debug_source("~/visual studio 2017/Projects/rproject2/rproject2/script.R")
###traceplots
require(ggthemes)
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 1000,                   thin = 5,                   cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
testModel2 <- stan(model_code = modPGp, data = data, iter = 10000, chains = 1)
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 1000,                   thin = 5,                   cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10, #campionamento system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 1000,                   thin = 1,                   cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) ) testModel2 <- stan(model_code = modPGp, data = data, iter = 10000, chains = 1)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 1000,                   thin = 1,                   cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha1; int beta1; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di output e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
#ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
# 4) Riassumi le caratteristiche principali della distribuzione a-posteriori
#   A vedere dal traceplot e dal density plot la sovrapposizione della 4 catene è buona. Magari dal density plot soprattutto si nota qualche discrepanza in più
#   Gelman invece mostra che non ci sono fattori di potenziale riduzione di scala per Lambda. Il che avalla la tesi sulla discreta bontà del modello.
#   Bontà avallata anche da Geweke, dato che tutte le catene sono comprese su valori Z fra -2 e 2
#   Il grafico Caterpillar mostra invece che la credibilità di lambda è alta fra circa 4,5 e 6,25
#   gg_pairs non funziona per qualche motivo
#   La funzione summary() aiuta a monitorare numericamente quanto detto fin'ora: vale a dire che le catene si sovrappongono e non ci sono problemi con il modello.
# 5) Ottieni la distribuzione prededittiva della futura osservazione con un campione di dimensione 10k. 
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 1000,                   thin = 1,                   cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
summary(fit)
median(outSim)
median(outSim$value)
mean(outSim$value)
min(outSim$value)
max(outSim$value)
range(outSim$value)
var(outSim$value)
sd(outSim$value)
IQR(outSim$value)
bwplot(outSim$value)
help(IQR)
help(bwplot)
??bwplot
median(outSim$value)
mean(outSim$value)
min(outSim$value)
max(outSim$value)
range(outSim$value)
var(outSim$value)
sd(outSim$value)
summary(fit)
summary(outSim)
summary(fit)
range(outSim$value)
summary(outSim)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha1; int beta1; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di output e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
#ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha1; int beta1; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   #cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha1; int beta1; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di output e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
#ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
# 4) Riassumi le caratteristiche principali della distribuzione a-posteriori
#   A vedere dal traceplot e dal density plot la sovrapposizione della 4 catene è buona. Magari dal density plot soprattutto si nota qualche discrepanza in più
#   Gelman invece mostra che non ci sono fattori di potenziale riduzione di scala per Lambda. Il che avalla la tesi sulla discreta bontà del modello.
#   Bontà avallata anche da Geweke, dato che tutte le catene sono comprese su valori Z fra -2 e 2
#   Il grafico Caterpillar mostra invece che la credibilità di lambda è alta fra circa 4,5 e 6,25
#   gg_pairs non funziona per qualche motivo
#   La funzione summary() aiuta a monitorare numericamente quanto detto fin'ora: vale a dire che le catene si sovrappongono e non ci sono problemi con il modello.
# 5) Ottieni la distribuzione prededittiva della futura osservazione con un campione di dimensione 10k. 
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 1000,                   thin = 1,                   cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
#    Riassumi le sue caratteristiche.
median(outSim$value)
mean(outSim$value)
min(outSim$value)
max(outSim$value)
range(outSim$value)
var(outSim$value)
sd(outSim$value)
summary(fit)
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_histogram(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue")
#    Mediamente arrivano 5,6 email al giorno. 
#    Il valore sta dentro alla distribuzione che risulta dal modello predittivo.
#    Si può dire che ci si può aspettare fra le 5 e le 6 email al giorno.
#    Guardando anche i valori osservati si può dire che in generale non ci sono "fughe" verso valori improbabili
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha1; int beta1; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di output e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
#ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
# 4) Riassumi le caratteristiche principali della distribuzione a-posteriori
#   A vedere dal traceplot e dal density plot la sovrapposizione della 4 catene è buona. Magari dal density plot soprattutto si nota qualche discrepanza in più
#   Gelman invece mostra che non ci sono fattori di potenziale riduzione di scala per Lambda. Il che avalla la tesi sulla discreta bontà del modello.
#   Bontà avallata anche da Geweke, dato che tutte le catene sono comprese su valori Z fra -2 e 2
#   Il grafico Caterpillar mostra invece che la credibilità di lambda è alta fra circa 4,5 e 6,25
#   gg_pairs non funziona per qualche motivo
#   La funzione summary() aiuta a monitorare numericamente quanto detto fin'ora: vale a dire che le catene si sovrappongono e non ci sono problemi con il modello.
# 5) Ottieni la distribuzione prededittiva della futura osservazione con un campione di dimensione 10k. 
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 4,                   iter = 10000,                   warmup = 1000,                   thin = 1,                   cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
#    Riassumi le sue caratteristiche.
median(outSim$value)
mean(outSim$value)
min(outSim$value)
max(outSim$value)
range(outSim$value)
var(outSim$value)
sd(outSim$value)
summary(fit)
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_histogram(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue") + geom_vline(xintercept = mean(outSim$value), color = "green")
#    Mediamente arrivano 5,6 email al giorno. 
#    Il valore sta dentro alla distribuzione che risulta dal modello predittivo.
#    Si può dire che ci si può aspettare fra le 5 e le 6 email al giorno.
#    Guardando anche i valori osservati si può dire che in generale non ci sono "fughe" verso valori improbabili
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 1000,                   thin = 1,                   cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
#    Riassumi le sue caratteristiche.
median(outSim$value)
mean(outSim$value)
min(outSim$value)
max(outSim$value)
range(outSim$value)
var(outSim$value)
sd(outSim$value)
summary(fit)
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_histogram(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue") + geom_vline(xintercept = mean(outSim$value), color = "green")
#    Mediamente arrivano 5,6 email al giorno. 
#    Il valore sta dentro alla distribuzione che risulta dal modello predittivo.
#    Si può dire che ci si può aspettare fra le 5 e le 6 email al giorno.
#    Guardando anche i valori osservati si può dire che in generale non ci sono "fughe" verso valori improbabili
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
#DATI FORNITI
Y <- c(7, 8, 9, 4, 7, 1, 8, 5, 6, 7, 0, 1, 6, 7, 9)
N <- sum(xtabs(~Y))
#DEFINISCO LE VARIABILI PER LAMBDA (parametri e iperparametri)
alpha0 <- 10 #totale mail arrivate in 
beta0 <- 3 #settimane
alpha1 <- alpha0 + sum(Y)
beta1 <- beta0 + N
# 1) Implementazione del modello
library(rstan)
data <- list(N, Y)
modPG <- '
data { int N; int Y[N]; int alpha1; int beta1; } transformed data{ }
parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
'
require(rstan)
iniTime <- date()
mod <- stan_model(model_code = modPG)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
# 2) Ottieni un campione simulato dalla a-posteriori
#SAMPLING E GENERAZIONE DELLE CATENE A POSTERIORI
library(rstudioapi)
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda"), #a noi interessa capire la distribuzione di Lambda, non di Y.                                        #Perchè dopo che si campiona lambda si capisce come distribuisce la Y                   chains = 4,                   iter = 25000,                   warmup = 10000,                   thin = 5,                   cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10,                                 adapt_delta = 0.8)   ) )
testModel <- stan(model_code = modPG, data = data, iter = 100, chains = 4)
# 3) Esplora le diagnostiche di output e discuti i risultati
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
#ggs_pairs(outSim, lower = list(continuous = "density"))
# riassunti numeri e diagnostica
summary(fit)
# 4) Riassumi le caratteristiche principali della distribuzione a-posteriori
#   A vedere dal traceplot e dal density plot la sovrapposizione della 4 catene è buona. Magari dal density plot soprattutto si nota qualche discrepanza in più
#   Gelman invece mostra che non ci sono fattori di potenziale riduzione di scala per Lambda. Il che avalla la tesi sulla discreta bontà del modello.
#   Bontà avallata anche da Geweke, dato che tutte le catene sono comprese su valori Z fra -2 e 2
#   Il grafico Caterpillar mostra invece che la credibilità di lambda è alta fra circa 4,5 e 6,25
#   gg_pairs non funziona per qualche motivo
#   La funzione summary() aiuta a monitorare numericamente quanto detto fin'ora: vale a dire che le catene si sovrappongono e non ci sono problemi con il modello.
# 5) Ottieni la distribuzione prededittiva della futura osservazione con un campione di dimensione 10k. 
modPGp <- '
data { int N; int Y[N]; int alpha1; int beta1; } parameters { real<lower=0> Lambda; }
transformed parameters {
}
model { Lambda ~ gamma(alpha1,beta1); Y ~ poisson(Lambda); }
generated quantities{
real Y_predict;
Y_predict = poisson_rng(Lambda);
}
'
iniTime <- date()
mod <- stan_model(model_code = modPGp)
endTime <- date();c(iniTime = iniTime, endTime = endTime)
#campionamento
system.time(   fit <<- sampling(mod,                   data = data,                   pars = c("Lambda", "Y_predict"),                   chains = 1,                   iter = 10000,                   warmup = 1000,                   thin = 1,                   cores = 4,                   seed = 19861986,                   control = list(max_treedepth = 10,                   adapt_delta = 0.8)   ) )
require(ggmcmc)
outSim <- ggs(fit)
print(outSim)
###traceplots
require(ggthemes)
ggs_traceplot(outSim) + theme_fivethirtyeight()
### Densita
ggs_density(outSim) + theme_solarized(light = TRUE)
### R cappello ovvero diagnostica di Gelman
ggs_Rhat(outSim) + xlab("R_hat")
### diagnostica di Geweke (solo per normali standardizzate)
ggs_geweke(outSim)
### diagnostica con Caterpillar
ggs_caterpillar(outSim)
#intervalli di credibilit?
ci(outSim)
# sintesi per coppie di parametri
ggs_pairs(outSim, lower = list(continuous = "density"))
#    Riassumi le sue caratteristiche.
median(outSim$value)
mean(outSim$value)
min(outSim$value)
max(outSim$value)
range(outSim$value)
var(outSim$value)
sd(outSim$value)
summary(fit)
# 6) Confronta i risultati ottenuti via simulazione MCMC con i risultati esatti sopra riportati
outSim = ggs(fit)
MailsOsservate <- c(mean(Y))
ggs_histogram(outSim, family = "Y_predict") + geom_vline(xintercept = MailsOsservate, color = "red") + geom_vline(xintercept = Y, color = "blue") + geom_vline(xintercept = mean(outSim$value), color = "green")
#    Mediamente arrivano 5,6 email al giorno. 
#    Il valore sta dentro alla distribuzione che risulta dal modello predittivo.
#    Si può dire che ci si può aspettare fra le 5 e le 6 email al giorno.
#    Guardando anche i valori osservati si può dire che in generale non ci sono "fughe" verso valori improbabili
